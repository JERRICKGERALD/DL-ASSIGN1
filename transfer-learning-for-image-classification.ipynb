{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a192aa88da02b06277cb238948494d84d5a5dd3f"
   },
   "source": [
    "This notebook is a complete solution for classifiying images (Logos in this case) by using Transfer Learn from a Keras pre-trained network ( currently InceptionV3). \n",
    "\n",
    "**About Data:** Data was collected by a group of students at **Atılım University** from food courts of several shooping mall at **Ankara, Turkey.** **5 Brand logos** were recorded and then extracted still images from these videos. Furthermore, there is a class  called \"**None**\" for images without any logos. Data is already splitted into two main directories as **Train and Test **for the user convenience. \n",
    "\n",
    "\n",
    "**About Notebook**: We need to develope a image classification model for helping blind people to be aware of the logos around themselves. Thus, we implement the solution by creating this notebook. During development, we noticed that there are many resources for Transfer Learning and Image Classification however, unfortunately, most of them are not either complete or lack of explanation. Thus, we decided to share this notebbok for anyone who would need similar requirements as we do.\n",
    "\n",
    "**Why study this notebook**: By studying this notebook you would be practicing on:\n",
    "* How to import **pre-trained** network model and its weights\n",
    "* How to define and use **Image Data Generators** for train, validation & test data\n",
    "* How to **agument** training data\n",
    "*  How to **plot images** in Image Data Generators\n",
    "*  How to **create your mode**l by **Transfer Learning** from InceptionV3 (or any Keras pre-trained model)\n",
    "*  How to set-up and use **Callbacks** such as **Checkpoints** and **EarlyStopping** \n",
    "* How to **compile** and **train** the model  by setting up **fit_generator**\n",
    "* How to calculate **steps_per_epoch** and **validation_steps** for fit_generator \n",
    "* How to monitor **Training History** using history object\n",
    "* How to **save** your model, best and last weights\n",
    "* How to **upload** your model, best and last weights from saved files\n",
    "* How to **evaulate** the model by using evaluate_generator\n",
    "* How to use your trained model to **predict** the classes of the test images by using **predict_generator**\n",
    "* How to **decode** the labels of the predicted classes\n",
    "* How to **save** the **predictions and actual labels** into a CSV file\n",
    "* How to **measeure the success** of your model by using **Accuracy**, **Precision**, and **Recall**\n",
    "* How to generate **classification_report**\n",
    "* How to prepare the **confusion matrix** to monitor the classification success\n",
    "* How to **plot** some sample predictions along with the corresponding true labels\n",
    "\n",
    "**In the end of this notebook**: We hope that you will have necessary skills to\n",
    "* **Understand** the Transfer Learning\n",
    "* **Apply** Image Detection\n",
    "* **Evaulate** the success of the classification\n",
    "* **Report** the results\n",
    "\n",
    "You can leave comments or suggection to improve this tutorial.\n",
    "Thanks in advanced!\n",
    "KMK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:07:10.776969Z",
     "start_time": "2019-01-09T13:07:10.422291Z"
    },
    "_uuid": "9f8f58a2f3d7f3f3aa45a6c139e4e0f243701d66"
   },
   "outputs": [],
   "source": [
    "# Standard data science libraries\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "from IPython.display import display_html\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "dataDirectory= \"../input/logos-bk-kfc-mcdonald-starbucks-subway-none/logos_v3_mini/logos3\" \n",
    "print(os.listdir(dataDirectory))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "db044790b763451aba23a280bf0389cdb34cc133"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7958be12e792b1182d9da83dd6c6c3ab72d4fa6b"
   },
   "source": [
    "To  transfer learning, we first need to download pre-trained model and its weights. To do so:\n",
    "* First from the right tool bar click \"**+Add Data**\" button.\n",
    "* Then search for \"**Keras Pretrained Models**\" and and add it to your notebook\n",
    "* Last run the below code to copy the necessary files into \"**Keras**\" directory where the notebook will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f9d738750cfa097a0ec3620830882ae683b6439c"
   },
   "outputs": [],
   "source": [
    "!rm -r ~/.keras\n",
    "!mkdir ~/.keras\n",
    "!mkdir ~/.keras/models\n",
    "# not enough space for both\n",
    "#!cp ../input/keras-pretrained-models/* ~/.keras/models/ \n",
    "#!cp ../input/vgg19/* ~/.keras/models\n",
    "!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n",
    "!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n",
    "#!cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1029127f7837680f1e44baf470ecccc0b1de3e78"
   },
   "source": [
    "# Dependicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:07:17.758376Z",
     "start_time": "2019-01-09T13:07:14.178196Z"
    },
    "_uuid": "a24ba7049747ccf65fedb8bd110e95085324ac69"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.inception_v3 import decode_predictions\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import model_from_json\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T14:22:47.433070Z",
     "start_time": "2019-01-05T14:22:47.430671Z"
    },
    "_uuid": "faf966e851d1929109be9017f0d1a2a270a89d7f"
   },
   "source": [
    "# Paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:07:22.876334Z",
     "start_time": "2019-01-09T13:07:22.873337Z"
    },
    "_uuid": "f919a9fbab28681b60e7b5c14497646bb25db626"
   },
   "outputs": [],
   "source": [
    "train_path = dataDirectory+'/train'\n",
    "test_path  = dataDirectory+'/test'\n",
    "print(os.listdir(train_path))\n",
    "print(os.listdir(test_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "990a61767775f5c98fd1e9e7c207562bfa713798"
   },
   "source": [
    "# Define Image Data Generators for train, validation & test data\n",
    "tf.keras.preprocessing.image.ImageDataGenerator:\n",
    "\n",
    "https://www.tensorflow.org/versions/r1.6/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n",
    "https://keras.io/preprocessing/image/\n",
    "\n",
    "Generate minibatches of image data with real-time data augmentation.\n",
    "The data will be looped over (in batches).\n",
    "\n",
    "## Arguments:\n",
    "\n",
    "### validation_split: \n",
    "Float. Fraction of images reserved for validation (strictly between 0 and 1).\n",
    "\n",
    "### featurewise_center: \n",
    "set input mean to 0 over the dataset.\n",
    "\n",
    "### samplewise_center: \n",
    "set each sample mean to 0.\n",
    "\n",
    "### featurewise_std_normalization: \n",
    "divide inputs by std of the dataset.\n",
    "\n",
    "### samplewise_std_normalization: \n",
    "divide each input by its std.\n",
    "\n",
    "### zca_whitening: \n",
    "apply ZCA whitening.\n",
    "\n",
    "### zca_epsilon: \n",
    "epsilon for ZCA whitening. Default is 1e-6.\n",
    "\n",
    "### rotation_range: \n",
    "degrees (0 to 180).\n",
    "\n",
    "### width_shift_range: \n",
    "fraction of total width, if < 1, or pixels if >= 1.\n",
    "\n",
    "### height_shift_range: \n",
    "fraction of total height, if < 1, or pixels if >= 1.\n",
    "\n",
    "### shear_range: \n",
    "shear intensity (shear angle in degrees).\n",
    "\n",
    "### zoom_range: \n",
    "amount of zoom. if scalar z, zoom will be randomly picked in the range [1-z, 1+z]. A sequence of two can be passed instead to select this range.\n",
    "\n",
    "etc...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:07:25.775332Z",
     "start_time": "2019-01-09T13:07:25.770269Z"
    },
    "_uuid": "09c3acf9ee5a13ec88e77ffabecac8db1f7730c2"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        fill_mode='nearest',\n",
    "    validation_split=0.2) # set validation split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5078767151346c15eba50498b5516258b9431ab9"
   },
   "source": [
    "# Data generators with flow from directory\n",
    "\n",
    "flow_from_directory\n",
    "\n",
    "https://keras.io/preprocessing/image/\n",
    "\n",
    "Takes the path to a directory & generates batches of augmented data.\n",
    "\n",
    "## Arguments\n",
    "\n",
    "### directory: \n",
    "Path to the target directory. It should contain *** one subdirectory per class ***. Any PNG, JPG, BMP, PPM or TIF images inside each of the subdirectories directory tree will be included in the generator. See this script for more details.\n",
    "\n",
    "### target_size: \n",
    "Tuple of integers (height, width), default: (256, 256). The dimensions to which all images found will be resized.\n",
    "\n",
    "### color_mode: \n",
    "One of \"grayscale\", \"rbg\", \"rgba\". Default: \"rgb\". Whether the images will be converted to have 1, 3, or 4 channels.\n",
    "\n",
    "### classes: \n",
    "Optional list of class subdirectories (e.g. ['dogs', 'cats']). Default: None. ***If not provided, the list of classes will be automatically inferred from the subdirectory names/structure under directory, where each subdirectory will be treated as a different class*** (and the order of the classes, which will map to the label indices, will be alphanumeric). The dictionary containing the mapping from class names to class indices can be obtained via the attribute class_indices.\n",
    "\n",
    "### class_mode: \n",
    "One of \"categorical\", \"binary\", \"sparse\", \"input\", or None. Default: \"categorical\". Determines the type of label arrays that are returned:\n",
    "\"categorical\" will be 2D one-hot encoded labels,\n",
    "\"binary\" will be 1D binary labels, \"sparse\" will be 1D integer labels,\n",
    "\"input\" will be images identical to input images (mainly used to work with autoencoders).\n",
    "If None, no labels are returned (the generator will only yield batches of image data, which is useful to use with model.predict_generator(),  model.evaluate_generator(), etc.). Please note that in case of class_mode None, the data still needs to reside in a subdirectory of directory for it to work correctly.\n",
    "\n",
    "### batch_size: \n",
    "Size of the batches of data (default: 32).\n",
    "\n",
    "### shuffle: \n",
    "Whether to shuffle the data (default: True)\n",
    "\n",
    "### seed: \n",
    "Optional random seed for shuffling and transformations.\n",
    "\n",
    "### save_to_dir: \n",
    "None or str (default: None). This allows you to optionally specify a directory to which to save the augmented pictures being generated (useful for visualizing what you are doing).\n",
    "\n",
    "### save_prefix: \n",
    "Str. Prefix to use for filenames of saved pictures (only relevant if save_to_dir is set).\n",
    "\n",
    "### save_format: \n",
    "One of \"png\", \"jpeg\" (only relevant if save_to_dir is set). Default: \"png\".\n",
    "\n",
    "### follow_links: \n",
    "Whether to follow symlinks inside class subdirectories (default: False).\n",
    "\n",
    "### subset: \n",
    "Subset of data (\"training\" or \"validation\") if *** validation_split *** is set in ImageDataGenerator.\n",
    "\n",
    "### interpolation: \n",
    "Interpolation method used to resample the image if the target size is different from that of the loaded image. Supported methods are \"nearest\", \"bilinear\", and \"bicubic\". If PIL version 1.1.3 or newer is installed, \"lanczos\" is also supported. If PIL version 3.4.0 or newer is installed,  \"box\" and \"hamming\" are also supported. By default, \"nearest\" is used.\n",
    "\n",
    "### Returns\n",
    "\n",
    "A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T18:33:27.798342Z",
     "start_time": "2019-01-05T18:33:27.753729Z"
    },
    "_uuid": "ffd65f86e656f872f6b0ab4065f0fa55b652bac0"
   },
   "source": [
    "## Load data from directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7cf66b184d5ca5d9ff60bc168ef304591dd82272"
   },
   "source": [
    "### Select classes by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:07:28.740441Z",
     "start_time": "2019-01-09T13:07:28.733768Z"
    },
    "_uuid": "836567f18b81934110967ed45d1787dc40a69bdc"
   },
   "outputs": [],
   "source": [
    "#['Burger King','HD Iskender','Kahve Dunyasi', 'KFC','McDonalds','Other', 'Ozsut','Popeyes',  'Starbucks', 'Subway', 'Tavuk Dunyasi'] \n",
    "selectedClasses = ['Burger King', 'KFC','McDonalds','Other', 'Starbucks', 'Subway'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bda919ca1dce144901b1cbc75157a27257ecaf5e"
   },
   "source": [
    "### Load images from the selected directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:07:32.410674Z",
     "start_time": "2019-01-09T13:07:32.094571Z"
    },
    "_uuid": "5043a42d1d912b9822d9dbc79991b232a159cfc3"
   },
   "outputs": [],
   "source": [
    "batchSize=32\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batchSize,\n",
    "    classes=selectedClasses,\n",
    "    subset='training') # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_path, # same directory as training data\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batchSize,\n",
    "    classes=selectedClasses,\n",
    "    subset='validation') # set as validation data\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_path, \n",
    "    target_size=(224,224), \n",
    "    classes=selectedClasses,\n",
    "    shuffle= False,\n",
    "    batch_size = batchSize)# set as test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c2987d3cda9be14d99cc81125db03bf27870894c"
   },
   "source": [
    "### Number of samples of each class in all data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:07:44.152795Z",
     "start_time": "2019-01-09T13:07:44.098003Z"
    },
    "_uuid": "0595d02d8435cd93b833a62c85ba3fcd0f0481bb"
   },
   "outputs": [],
   "source": [
    "print (\"In train_generator \")\n",
    "for cls in range(len (train_generator.class_indices)):\n",
    "    print(selectedClasses[cls],\":\\t\",list(train_generator.classes).count(cls))\n",
    "print (\"\") \n",
    "\n",
    "print (\"In validation_generator \")\n",
    "for cls in range(len (validation_generator.class_indices)):\n",
    "    print(selectedClasses[cls],\":\\t\",list(validation_generator.classes).count(cls))\n",
    "print (\"\") \n",
    "\n",
    "print (\"In test_generator \")\n",
    "for cls in range(len (test_generator.class_indices)):\n",
    "    print(selectedClasses[cls],\":\\t\",list(test_generator.classes).count(cls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T14:25:22.301409Z",
     "start_time": "2019-01-05T14:25:22.299279Z"
    },
    "_uuid": "ecfeaabf4bc7575099f847278db3a57f3c2697ec"
   },
   "source": [
    "# Auxilary Functions for ploting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:07:56.700309Z",
     "start_time": "2019-01-09T13:07:56.689889Z"
    },
    "_uuid": "3d7b81115db39b7e1a8e7b6d6410939ca0323697"
   },
   "outputs": [],
   "source": [
    "#plots images with labels within jupyter notebook\n",
    "def plots(ims, figsize = (22,22), rows=4, interp=False, titles=None, maxNum = 9):\n",
    "    if type(ims[0] is np.ndarray):\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if(ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "           \n",
    "    f = plt.figure(figsize=figsize)\n",
    "    #cols = len(ims) //rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    cols = maxNum // rows if maxNum % 2 == 0 else maxNum//rows + 1\n",
    "    #for i in range(len(ims)):\n",
    "    for i in range(maxNum):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=20)\n",
    "        plt.imshow(ims[i], interpolation = None if interp else 'none')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d97813aa2622426659aac3fb22f396c88540aed9"
   },
   "source": [
    "# Plot some train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:08:00.355468Z",
     "start_time": "2019-01-09T13:07:59.925891Z"
    },
    "_uuid": "263992d1d13980b31f954df0cb3052d86d5e61bb"
   },
   "outputs": [],
   "source": [
    "train_generator.reset()\n",
    "imgs, labels = train_generator.next()\n",
    "\n",
    "#print(labels)\n",
    "\n",
    "labelNames=[]\n",
    "labelIndices=[np.where(r==1)[0][0] for r in labels]\n",
    "#print(labelIndices)\n",
    "\n",
    "for ind in labelIndices:\n",
    "    for labelName,labelIndex in train_generator.class_indices.items():\n",
    "        if labelIndex == ind:\n",
    "            #print (labelName)\n",
    "            labelNames.append(labelName)\n",
    "\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:44:49.433304Z",
     "start_time": "2019-01-09T13:44:47.755121Z"
    },
    "_uuid": "e17055210f95bc60b695963ba9d334d897ed7d46",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plots(imgs, rows=4, titles = labelNames, maxNum=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e43e886a0f0dbcb0e140a04e15e2671e4909489"
   },
   "source": [
    "# Create model by Transfer Learning from InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:08:27.458145Z",
     "start_time": "2019-01-09T13:08:16.468492Z"
    },
    "_uuid": "11f0af64c03f1aaa286072d9996df84df3c09ed0"
   },
   "outputs": [],
   "source": [
    "#InceptionV3\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=(224, 224,3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dropout(0.5)(x)\n",
    "# and a sofymax/logistic layer -- we have 6 classes\n",
    "predictions = Dense(len(selectedClasses), activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "295d15ab6bd00683f648206fca5110d08cefe427"
   },
   "source": [
    "# Usage of callbacks\n",
    "\n",
    "https://keras.io/callbacks/\n",
    "\n",
    "\n",
    "A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training.\n",
    "\n",
    "\n",
    "## History\n",
    "\n",
    "keras.callbacks.History()\n",
    "\n",
    "Callback that records events into a History object.\n",
    "\n",
    "This callback is automatically applied to every Keras model. \n",
    "***The History object gets returned by the fit method of models.***\n",
    "\n",
    "\n",
    "## ModelCheckpoint\n",
    "\n",
    "***keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)***\n",
    "\n",
    "\n",
    "Save the model after every epoch.\n",
    "\n",
    "\n",
    "filepath can contain named formatting options, which will be filled the value of epoch and keys in logs (passed in on_epoch_end).\n",
    "\n",
    "\n",
    "For example: if filepath is weights.{epoch:02d}-{val_loss:.2f}.hdf5, then the model checkpoints will be saved with the epoch number and the validation loss in the filename.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "***filepath:*** string, path to save the model file. \n",
    "\n",
    "*** monitor:*** quantity to monitor. \n",
    "\n",
    "***verbose:**** verbosity mode, 0 or 1. \n",
    "\n",
    "***save_best_only:*** if save_best_only=True, the latest best model according to the quantity monitored will not be overwritten. \n",
    "\n",
    "\n",
    "***mode:**** one of {auto, min, max}. \n",
    "\n",
    "***If save_best_only=True,**** the decision to overwrite the current save file is made based on either the maximization or the minimization of the monitored quantity. For val_acc, this should be max, for val_loss this should be min, etc. \n",
    "\n",
    "***In auto mode,*** the direction is automatically inferred from the name of the monitored quantity. \n",
    "\n",
    "***save_weights_only:*** if True, then only the model's weights will be saved (model.save_weights(filepath)), else the full model is saved (model.save(filepath)). \n",
    "\n",
    "***period:*** Interval (number of epochs) between checkpoints.\n",
    "\n",
    "### Example:\n",
    "\n",
    "***Atutomatic rename with epoch number and val accuracy:***\n",
    "\n",
    "filepath=\"checkpoints/weights-improvement-epeoch-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "## EarlyStopping\n",
    "\n",
    "***keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)***\n",
    "\n",
    "Stop training when a monitored quantity has stopped improving.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "***monitor:*** quantity to be monitored. \n",
    "\n",
    "***min_delta:*** minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement. \n",
    "\n",
    "***patience:*** number of epochs with no improvement after which training will be stopped. \n",
    "\n",
    "***verbose:*** verbosity mode. \n",
    "\n",
    "***mode:*** one of {auto, min, max}. **In min mode,** training will stop when the quantity monitored has stopped decreasing; **in max mode** it will stop when the quantity monitored has stopped increasing; **in auto mode,** the direction is automatically inferred from the name of the monitored quantity. \n",
    "\n",
    "***baseline:*** Baseline value for the monitored quantity to reach. Training will stop if the model doesn't show improvement over the baseline. \n",
    "\n",
    "***restore_best_weights:*** whether to restore model weights from the epoch with the best value of the monitored quantity. **If False,** the model weights obtained at the last step of training are used.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:08:48.701546Z",
     "start_time": "2019-01-09T13:08:48.695053Z"
    },
    "_uuid": "60d683159d4600d64a2a682c7331060bd6003cd8"
   },
   "outputs": [],
   "source": [
    "#Atutomatic rename with epoch number and val accuracy:\n",
    "#filepath=\"checkpoints/weights-improvement-epeoch-{epoch:02d}-val_acc-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "\n",
    " \n",
    "modelName= \"InceptionTutorial\"\n",
    "#save the best weights over the same file with the model name\n",
    "\n",
    "#filepath=\"checkpoints/\"+modelName+\"_bestweights.hdf5\"\n",
    "filepath=modelName+\"_bestweights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "341249dc9e3894599e285872f95b4247096fef1f"
   },
   "source": [
    "# Compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:08:53.428701Z",
     "start_time": "2019-01-09T13:08:53.392290Z"
    },
    "_uuid": "384512b8dc2bae349f1183f400fc0c33d6baa161"
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "495d2e73cb7e39339f0620a63e3d27770b4405b1"
   },
   "source": [
    "# Train the model\n",
    "\n",
    "## Set up fit_generator\n",
    "https://keras.io/models/model/\n",
    "\n",
    "fit_generator(generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
    "\n",
    "Trains the model on data generated batch-by-batch by a Python generator (or an instance of Sequence).\n",
    "\n",
    "The generator is run in parallel to the model, for efficiency. For instance, this allows you to do real-time data augmentation on images on CPU in parallel to training your model on GPU.\n",
    "\n",
    "The use of keras.utils.Sequence guarantees the ordering and guarantees the single use of every input per epoch when using use_multiprocessing=True.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "#### generator: \n",
    "A generator or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing. The output of the generator must be either\n",
    "* a tuple (inputs, targets)\n",
    "* a tuple (inputs, targets, sample_weights).\n",
    "This tuple (a single output of the generator) makes a single batch. Therefore, all arrays in this tuple must have the same length (equal to the size of this batch). Different batches may have different sizes. For example, the last batch of the epoch is commonly smaller than the others, if the size of the dataset is not divisible by the batch size. The generator is expected to loop over its data indefinitely. An epoch finishes when steps_per_epoch batches have been seen by the model.\n",
    "\n",
    "#### steps_per_epoch: \n",
    "Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. ***It should typically be equal to the number of samples of your dataset divided by the batch size***. Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
    "\n",
    "#### epochs: \n",
    "Integer. Number of epochs to train the model. An epoch is an iteration over the entire data provided, as defined by steps_per_epoch. Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached.\n",
    "\n",
    "#### verbose: \n",
    "Integer. 0, 1, or 2. Verbosity mode. 0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
    "\n",
    "#### callbacks: \n",
    "List of keras.callbacks.Callback instances. List of callbacks to apply during training. See callbacks.\n",
    "validation_data: This can be either\n",
    "\n",
    "* a generator or a Sequence object for the validation data\n",
    "* tuple (x_val, y_val)\n",
    "* tuple (x_val, y_val, val_sample_weights)\n",
    "on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data.\n",
    "\n",
    "#### validation_steps: \n",
    "Only relevant if validation_data is a generator. Total number of steps (batches of samples) to yield from validation_data generator before stopping at the end of every epoch. ***It should typically be equal to the number of samples of your validation dataset divided by the batch size.*** Optional for Sequence: if unspecified, will use the len(validation_data) as a number of steps.\n",
    "\n",
    "#### class_weight: \n",
    "Optional dictionary mapping class indices (integers) to a weight (float) value, used for weighting the loss function (during training only). This can be useful to tell the model to \"pay more attention\" to samples from an under-represented class.\n",
    "\n",
    "#### max_queue_size: \n",
    "Integer. Maximum size for the generator queue. If unspecified, max_queue_size will default to 10.\n",
    "\n",
    "#### workers: \n",
    "Integer. Maximum number of processes to spin up when using process-based threading. If unspecified, workers will default to 1. If 0, will execute the generator on the main thread.\n",
    "\n",
    "#### use_multiprocessing: \n",
    "Boolean. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes.\n",
    "\n",
    "#### shuffle: \n",
    "Boolean. Whether to shuffle the order of the batches at the beginning of each epoch. Only used with instances of Sequence (keras.utils.Sequence). Has no effect when steps_per_epoch is not None.\n",
    "initial_epoch: Integer. Epoch at which to start training (useful for resuming a previous training run).\n",
    "\n",
    "### Returns\n",
    "\n",
    "#### A History object. \n",
    "Its History.history attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values (if applicable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca07f5562716bb9826c10bc6f28404712adfc997"
   },
   "source": [
    "### Calculate steps_per_epoch and validation_steps For fit_generator \n",
    "Integer. Total number of steps (batches of samples) to yield from generator before declaring one epoch finished and starting the next epoch. ***It should typically be equal to the number of samples of your dataset divided by the batch size.*** Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:09:01.148991Z",
     "start_time": "2019-01-09T13:09:01.145694Z"
    },
    "_uuid": "8e2d8697a0879f08a81ac3e60d9af38c9744a382"
   },
   "outputs": [],
   "source": [
    "stepsPerEpoch= (train_generator.samples+ (batchSize-1)) // batchSize\n",
    "print(\"stepsPerEpoch: \", stepsPerEpoch)\n",
    "\n",
    "validationSteps=(validation_generator.samples+ (batchSize-1)) // batchSize\n",
    "print(\"validationSteps: \", validationSteps)\n",
    "\n",
    "\n",
    "#validationSteps=(test_generator.samples+ (batchSize-1)) // batchSize\n",
    "#print(\"validationSteps: \", validationSteps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa14c843f83ff9d15695c67d29ef0b1bfe0c332c"
   },
   "source": [
    "## Train\n",
    "Run more epochs for increasing the accuracy. For example:\n",
    "\n",
    "**epochs = 30**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:22:21.292429Z",
     "start_time": "2019-01-09T13:09:07.699592Z"
    },
    "_uuid": "58a89d7b09c137e98e04da2183cff05534b92acc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_generator.reset()\n",
    "validation_generator.reset()\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    validation_data = validation_generator,\n",
    "    epochs = 3,\n",
    "    steps_per_epoch = stepsPerEpoch,\n",
    "    validation_steps= validationSteps,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T15:02:52.400593Z",
     "start_time": "2019-01-04T15:02:52.379084Z"
    },
    "_uuid": "4480be219fcbae7945a5beb240f48fb03b7a7724"
   },
   "source": [
    "## Show Training History\n",
    "We can plot the accuracy and loss values for each epoch using the history object as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:26:39.841034Z",
     "start_time": "2019-01-09T13:26:39.550017Z"
    },
    "_uuid": "d34127320eedf15d4098938111e3fbcbc65997ac"
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T15:03:36.797882Z",
     "start_time": "2019-01-04T15:03:36.735271Z"
    },
    "_uuid": "d27c1f115b5dbe469520a380c04f55d8286713ee"
   },
   "source": [
    "# Save the model and last weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:27:25.956442Z",
     "start_time": "2019-01-09T13:27:25.489749Z"
    },
    "_uuid": "63f06adfdffb63e8fcaad039b1af3386bce6940d"
   },
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(timestr+\"_\"+modelName+\"_MODEL_3\"+\".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(timestr+\"_\"+modelName+\"_3_LAST_WEIGHTS_\"+\".h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61b3eed9d560a19f0e7bfe8a52db4d89c4bc3c7e"
   },
   "source": [
    "# Upload the model and best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T20:31:16.942396Z",
     "start_time": "2019-01-07T20:31:06.361077Z"
    },
    "_uuid": "35cc7970fe3123432bd957969e47b5167600b834"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open('20190107_220958_InceptionTutorial_MODEL_3.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T15:24:24.756231Z",
     "start_time": "2019-01-08T15:24:23.557099Z"
    },
    "_uuid": "f65fa75bddedc9712ee2207ce8c5981b8c0ecbbe"
   },
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "model.load_weights(\"InceptionTutorial_bestweights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ed6685fc8995b6b85a96253cfe0d015f1611cd9"
   },
   "source": [
    "# Evaulate the model\n",
    "\n",
    "***evaluate_generator(generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)***\n",
    "\n",
    "Evaluates the model on a data generator.\n",
    "\n",
    "The generator should return the same kind of data as accepted by test_on_batch.\n",
    "\n",
    "## Arguments\n",
    "\n",
    "***generator:*** Generator yielding tuples (inputs, targets) or (inputs, targets, sample_weights) or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing.\n",
    "\n",
    "***steps:*** Total number of steps (batches of samples) to yield from generator before stopping. Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
    "\n",
    "***max_queue_size:*** maximum size for the generator queue\n",
    "\n",
    "***workers:*** Integer. Maximum number of processes to spin up when using process based threading. If unspecified, workers will default to 1. If 0, will execute the generator on the main thread.\n",
    "\n",
    "***use_multiprocessing:*** if True, use process based threading. Note that because this implementation relies on multiprocessing, you should not pass non picklable arguments to the generator as they can't be passed easily to children processes.\n",
    "\n",
    "***verbose:*** verbosity mode, 0 or 1.\n",
    "\n",
    "***Returns***\n",
    "Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute model.metrics_names will give you the display labels for the scalar outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:28:15.796586Z",
     "start_time": "2019-01-09T13:28:11.237889Z"
    },
    "_uuid": "c0b173b03c4adb8e0f4eba3c8eb47842bfce3e41"
   },
   "outputs": [],
   "source": [
    "validation_generator.reset()\n",
    "score = model.evaluate_generator(validation_generator, (validation_generator.samples + (batchSize-1)) //batchSize)\n",
    "print(\"For validation data set; Loss: \",score[0],\" Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:28:23.848007Z",
     "start_time": "2019-01-09T13:28:21.568482Z"
    },
    "_uuid": "99523b3393cee02ea1b48d216687159a26192683"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "score = model.evaluate_generator(test_generator, (test_generator.samples + (batchSize-1)) // batchSize)\n",
    "print(\"For test data set; Loss: \",score[0],\" Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c0af8d58b1857a6dad235e28c9ffa99ed896dd17"
   },
   "source": [
    "# Predict Generator\n",
    "https://keras.io/models/sequential/\n",
    "\n",
    "predict_generator(generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
    "\n",
    "Generates predictions for the input samples from a data generator.\n",
    "\n",
    "The generator should return the same kind of data as accepted by predict_on_batch.\n",
    "\n",
    "## Arguments\n",
    "\n",
    "### generator: \n",
    "Generator yielding batches of input samples or an instance of Sequence (keras.utils.Sequence) object in order to avoid duplicate data when using multiprocessing.\n",
    "\n",
    "### steps: \n",
    "Total number of steps (batches of samples) to yield from generator before stopping. Optional for Sequence: if unspecified, will use the len(generator) as a number of steps.\n",
    "\n",
    "### max_queue_size: \n",
    "Maximum size for the generator queue.\n",
    "\n",
    "### workers: \n",
    "Integer. Maximum number of processes to spin up when using process based threading. If unspecified, workers will default to 1. If 0, will execute the generator on the main thread.\n",
    "\n",
    "### use_multiprocessing: \n",
    "If True, use process based threading. Note that because this implementation relies on multiprocessing, you should not pass non picklable arguments to the generator as they can't be passed easily to children processes.\n",
    "\n",
    "### verbose: \n",
    "verbosity mode, 0 or 1.\n",
    "\n",
    "## Returns\n",
    "\n",
    "Numpy array(s) of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32af6eb616d371aacc55a172b93bd6cae12991f5"
   },
   "source": [
    "# Make Predictions\n",
    "\n",
    "You need to **reset** the test_generator before whenever you call the predict_generator. This is important, if you forget to reset the test_generator you will get outputs in a weird order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:28:41.444803Z",
     "start_time": "2019-01-09T13:28:38.501881Z"
    },
    "_uuid": "c43f00125130013ab750d1b5befbf4269d9e5492"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "testStep = (test_generator.samples + (batchSize-1)) // batchSize\n",
    "print(\"testStep: \", testStep)\n",
    "predictions = model.predict_generator(test_generator, steps = testStep ,  verbose = 1)\n",
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:28:45.298195Z",
     "start_time": "2019-01-09T13:28:45.284963Z"
    },
    "_uuid": "137a443de66fab9182e206d778fb94359b0628d3"
   },
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f6bddac81172b54c938866715e95953a69560b2"
   },
   "source": [
    "\n",
    "## Decode Labels\n",
    "\n",
    "Now ***predictions*** has the probabilities for 6 classes for each test case!\n",
    "\n",
    "We can find the class with the highest probability as the prediction label as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:28:48.698938Z",
     "start_time": "2019-01-09T13:28:48.624694Z"
    },
    "_uuid": "f61ef1ec90bbf8c3d4edfef723ab649e9ffa56a6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(predictions,axis=1)\n",
    "print(predicted_class_indices)\n",
    "len(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d0679be24753b6963b63ac4faae3537e5d18935"
   },
   "source": [
    "***predicted_class_indices** has the predicted labels, but you can’t simply tell what the predictions are, because all you can see is numbers like 0,1,4,1,0,6…\n",
    "and most importantly you need to map the predicted labels with their unique ids such as filenames to find out what you predicted for which image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:28:52.602535Z",
     "start_time": "2019-01-09T13:28:52.594836Z"
    },
    "_uuid": "4ac4553ca941927a6c47093bafec7b4e1de1e345"
   },
   "outputs": [],
   "source": [
    "labels = (test_generator.class_indices)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:28:55.025943Z",
     "start_time": "2019-01-09T13:28:55.022040Z"
    },
    "_uuid": "b7252d18680df0641e3957932c19951b5c951c1e"
   },
   "outputs": [],
   "source": [
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:29:00.909221Z",
     "start_time": "2019-01-09T13:29:00.905333Z"
    },
    "_uuid": "d41cc4d806a2a534966687a622d3154379347014"
   },
   "outputs": [],
   "source": [
    "predictedLables= [labels[k] for k in predicted_class_indices]\n",
    "print(predictedLables)\n",
    "len(predictedLables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eff1c04c55e98d65ae433ffcc594b6f5777e6498"
   },
   "source": [
    "***predictedLabels*** have the labels predicted by the model. We need to locate ***the actual labels*** for the same test data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:29:06.957568Z",
     "start_time": "2019-01-09T13:29:06.952552Z"
    },
    "_uuid": "759efefb9cff5d1855e8c28e04d3b0c294fd8ba9"
   },
   "outputs": [],
   "source": [
    "actualLables= [labels[k] for k in test_generator.classes]\n",
    "print(actualLables)\n",
    "len(actualLables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d1ca75e80268f5b3b3aa56687a08d0036f1a84f"
   },
   "source": [
    "# Evaulate the results\n",
    "\n",
    "Below, we will see several methods for evaluating a classifier.\n",
    "\n",
    "More on http://www.cse.chalmers.se/~richajo/dit865/files/Classification%20evaluation%20examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0ce00396ec818742faeae5a5c9b12c3043115555"
   },
   "source": [
    "## Accuracy\n",
    "The most classical evaluation metric for classifiers is the accuracy, which corresponds to the proportion of correctly classified instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:29:16.498931Z",
     "start_time": "2019-01-09T13:29:16.429254Z"
    },
    "_uuid": "93fe24e2e91f4db7483c01ef7c207f11659983fc"
   },
   "outputs": [],
   "source": [
    "accuracy_score(actualLables, predictedLables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "55079961a13f1ed44e19a9ef7d6c0a60d9137204"
   },
   "source": [
    "## Evaluation metrics based on a confusion matrix\n",
    "\n",
    "A confusion matrix is such that the cell at row  i  and column  j  is equal to the number of observations known to be in group  i  but predicted to be in group  j .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:29:20.900414Z",
     "start_time": "2019-01-09T13:29:20.855290Z"
    },
    "_uuid": "656c4a43531f3e31e475f6acac3d5a3da2b4da6a"
   },
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(actualLables, predictedLables)\n",
    "print(labels)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "903d1d27ac4156f1241233cf4c6263def349886e"
   },
   "source": [
    "## The precision and recall metrics\n",
    "Several metrics can be derived from a confusion matrix. (See the Wikipedia article.) In particular, they tend to be based on the special case of a confusion matrix, where we assign one class to be the \"positive\" class that is important to us. This is sometimes called a table of confusion. In such a table, we speak of true positives, false positives, false negatives, and true negatives.\n",
    "\n",
    "The precision and recall metrics are probably the most common metrics derived from such a table.\n",
    "\n",
    "P  = TP / (TP + FP)\n",
    "\n",
    "R  = TP / (TP + FN)\n",
    "\n",
    "For example, What's the precision and recall of 'Burger King' in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18945d16c88ae6d482751ce4feaa8b25b1c6d825"
   },
   "source": [
    "The utility function ***classification_report*** prints the precision and recall values for all the categories. (The  F1  score combines the precision and recall values into a single value.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:29:50.508436Z",
     "start_time": "2019-01-09T13:29:50.431035Z"
    },
    "_uuid": "a9fb3245cf878eb98e82d5bbcbc1f73df53836d0"
   },
   "outputs": [],
   "source": [
    "print(classification_report(actualLables, predictedLables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:30:23.304716Z",
     "start_time": "2019-01-09T13:30:23.261018Z"
    },
    "_uuid": "2444b26d44da948cd8b31ca8a7c709587a7a3036"
   },
   "outputs": [],
   "source": [
    "recall_score( actualLables, predictedLables,average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:30:25.298258Z",
     "start_time": "2019-01-09T13:30:25.276103Z"
    },
    "_uuid": "246423d14fd50146b3d9b090288c28286be429c0"
   },
   "outputs": [],
   "source": [
    "precision_score( actualLables, predictedLables,average='weighted') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8cf61d82112234efcbf0567636561e5bbf497ae5"
   },
   "source": [
    "## Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:30:29.370813Z",
     "start_time": "2019-01-09T13:30:29.359923Z"
    },
    "_uuid": "013e3989b0aa81e31f27b73f05febf25d310ee68"
   },
   "outputs": [],
   "source": [
    "#Prepared code that is taken from SKLearn Website, Creates Confusion Matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:30:33.281617Z",
     "start_time": "2019-01-09T13:30:32.665103Z"
    },
    "_uuid": "e08bfa3da86fe9847d3d6aa6620816720816ae2d"
   },
   "outputs": [],
   "source": [
    "cm_plot_labels = selectedClasses\n",
    "plot_confusion_matrix(matrix,cm_plot_labels, normalize=False\n",
    "                      , title = 'Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39b9fc47318dcd75be76a97e410579c5f7267827"
   },
   "source": [
    "# Save Predictions\n",
    "Finally, save the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:31:14.133995Z",
     "start_time": "2019-01-09T13:31:14.127518Z"
    },
    "_uuid": "0d6c0c865d8c60f7b32a70191b8c7fb44c52350d"
   },
   "outputs": [],
   "source": [
    "filenames=test_generator.filenames\n",
    "directory= test_generator.directory\n",
    "results=pd.DataFrame({\"Directory\":directory,\n",
    "                      \"Filename\":filenames,\n",
    "                      \"Predictions\":predictedLables,\n",
    "                     \"Actuals\": actualLables })\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f19385ec7c555892bb8f0a6e9f5fd25f763275ec"
   },
   "source": [
    "# Show some sample predictions with corresponding true labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-09T13:42:41.071454Z",
     "start_time": "2019-01-09T13:42:35.745755Z"
    },
    "_uuid": "2b2216bc0d194f5b89e5ad691c9fe62f800aa301"
   },
   "outputs": [],
   "source": [
    "#import glob\n",
    "#import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "res = results[260:280]\n",
    "\n",
    "images = []\n",
    "#for img_path in glob.glob('images/*.jpg'):\n",
    "for img_path in \"./\"+res['Directory']+\"/\"+res['Filename']:\n",
    "    images.append(mpimg.imread(img_path))\n",
    "\n",
    "plt.figure(figsize=(80,80))\n",
    "columns = 4\n",
    "for i, image in enumerate(images):\n",
    "    ax= plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "    ax.set_title(res['Actuals'].iloc[i]+\" \"+res['Predictions'].iloc[i], fontsize=40)\n",
    "    plt.imshow(image)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "380.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "493px",
    "left": "1540px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
